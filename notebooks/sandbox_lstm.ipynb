{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3b363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, GaussianNoise, LSTM, Bidirectional, Dropout, Dense, Conv1D\n",
    "from tensorflow.keras import regularizers, backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, R2Score\n",
    "\n",
    "# Get the absolute path to the project directory\n",
    "project_dir = os.path.abspath(\"..\")\n",
    "\n",
    "# Append the project directory to sys.path\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "    \n",
    "from src.predictionModule.LoadupSamples import LoadupSamples\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb954e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"idxAfterPrediction\": 3,\n",
    "    'timesteps': 60,\n",
    "    'target_option': 'mean',\n",
    "    \"LoadupSamples_time_scaling_stretch\": True,\n",
    "    \"LoadupSamples_time_inc_factor\": 10,\n",
    "    \n",
    "    \"TreeTime_lstm_units\": 32,\n",
    "    \"TreeTime_lstm_num_layers\": 3,\n",
    "    \"TreeTime_lstm_dropout\": 0.00001,\n",
    "    \"TreeTime_lstm_recurrent_dropout\": 0.00001,\n",
    "    \"TreeTime_lstm_learning_rate\": 0.001,\n",
    "    \"TreeTime_lstm_optimizer\": \"adam\",\n",
    "    \"TreeTime_lstm_bidirectional\": True,\n",
    "    \"TreeTime_lstm_batch_size\": 2**12,\n",
    "    \"TreeTime_lstm_epochs\": 2,\n",
    "    \"TreeTime_lstm_l1\": 0.00001,\n",
    "    \"TreeTime_lstm_l2\": 0.00001,\n",
    "    \"TreeTime_inter_dropout\": 0.00001,\n",
    "    \"TreeTime_input_gaussian_noise\": 0.00001,\n",
    "    \"TreeTime_lstm_conv1d\": True,\n",
    "    \"TreeTime_lstm_conv1d_kernel_size\": 3,\n",
    "    \"TreeTime_lstm_loss\": \"mse\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c306cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_group = \"group_regOHLCV_over5years\"\n",
    "\n",
    "eval_date = datetime.date(year=2025, month=6, day=13)\n",
    "start_train_date = datetime.date(year=2020, month=1, day=1)\n",
    "\n",
    "ls = LoadupSamples(\n",
    "    train_start_date=start_train_date,\n",
    "    test_dates=[eval_date],\n",
    "    group=stock_group,\n",
    "    group_type=\"Time\",\n",
    "    params=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a74d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN values found in training time features. 1806 Samples removed.\n"
     ]
    }
   ],
   "source": [
    "ls.load_samples(main_path = \"../src/featureAlchemy/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21232b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xtree = ls.train_Xtree\n",
    "train_ytree = ls.train_ytree\n",
    "train_Xtime = ls.train_Xtime\n",
    "train_ytime = ls.train_ytime\n",
    "\n",
    "test_Xtree = ls.test_Xtree\n",
    "test_ytree = ls.test_ytree\n",
    "test_Xtime = ls.test_Xtime\n",
    "test_ytime = ls.test_ytime\n",
    "\n",
    "treenames = ls.featureTreeNames\n",
    "timenames = ls.featureTimeNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d8ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(train_ytree)) if stock_group == \"Time\" else None\n",
    "print(np.mean(train_ytime)) if stock_group == \"Tree\" else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80dc05d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FeatureLSTM_Price' 'FeatureLSTM_Volume']\n",
      "(2477819, 90, 2)\n"
     ]
    }
   ],
   "source": [
    "print(timenames)\n",
    "print(train_Xtime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6d76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tf(params, train_Xtime=train_Xtime, train_ytime=train_ytime, training_ratio=0.95):\n",
    "    # Hyperparameters to tune\n",
    "    lstm_units = params[\"TreeTime_lstm_units\"]\n",
    "    num_layers = params[\"TreeTime_lstm_num_layers\"]\n",
    "    dropout = params[\"TreeTime_lstm_dropout\"]\n",
    "    recurrent_dropout = params[\"TreeTime_lstm_recurrent_dropout\"]\n",
    "    learning_rate = params[\"TreeTime_lstm_learning_rate\"]\n",
    "    optimizer_name = params[\"TreeTime_lstm_optimizer\"]\n",
    "    bidirectional = params[\"TreeTime_lstm_bidirectional\"]\n",
    "    batch_size = params[\"TreeTime_lstm_batch_size\"]\n",
    "    epochs = params[\"TreeTime_lstm_epochs\"]\n",
    "    loss_name = params[\"TreeTime_lstm_loss\"]\n",
    "\n",
    "    # Regularization hyperparameters\n",
    "    l1 = params.get(\"TreeTime_lstm_l1\", 0.0)\n",
    "    l2 = params.get(\"TreeTime_lstm_l2\", 0.0)\n",
    "    inter_dropout = params.get(\"TreeTime_inter_dropout\", 0.0)\n",
    "    noise_std = params.get(\"TreeTime_input_gaussian_noise\", 0.0)\n",
    "\n",
    "    # Conv1D option\n",
    "    use_conv1d = params.get(\"TreeTime_lstm_conv1d\", False)\n",
    "    conv_filters = lstm_units\n",
    "    conv_kernel = params.get(\"TreeTime_lstm_conv1d_kernel_size\", 3)\n",
    "    X_full, y_full = train_Xtime, train_ytime\n",
    "    n_total = X_full.shape[0]\n",
    "    split_at = int(n_total * training_ratio)\n",
    "    X_train, X_holdout = X_full[:split_at], X_full[split_at:]\n",
    "    y_train, y_holdout = y_full[:split_at], y_full[split_at:]\n",
    "\n",
    "    # Build model\n",
    "    model = Sequential([Input(shape=train_Xtime.shape[1:])])\n",
    "    # Add Gaussian noise to inputs\n",
    "    if noise_std > 0:\n",
    "        model.add(GaussianNoise(noise_std))\n",
    "    # Add Conv1D layer if opted in\n",
    "    if use_conv1d:\n",
    "        model.add(Conv1D(filters=conv_filters,\n",
    "                        kernel_size=conv_kernel,\n",
    "                        padding='same',\n",
    "                        activation='linear'))\n",
    "    # Add LSTM layers with regularization and dropout\n",
    "    for i in range(num_layers):\n",
    "        return_seq = i < (num_layers - 1)\n",
    "        lstm_layer = LSTM(\n",
    "            lstm_units,\n",
    "            return_sequences=return_seq,\n",
    "            dropout=dropout,\n",
    "            recurrent_dropout=recurrent_dropout,\n",
    "            kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)\n",
    "        )\n",
    "        if bidirectional:\n",
    "            model.add(Bidirectional(lstm_layer))\n",
    "        else:\n",
    "            model.add(lstm_layer)\n",
    "        # Add dropout between layers\n",
    "        if inter_dropout > 0 and return_seq:\n",
    "            model.add(Dropout(inter_dropout))\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear', kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)))\n",
    "    # Optimizer\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    def quantile_loss(q):\n",
    "        def loss(y_true, y_pred):\n",
    "            e = y_true - y_pred\n",
    "            return tf.reduce_mean(tf.maximum(q*e, (q-1)*e))\n",
    "        return loss\n",
    "    def r2_keras(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Returns R^2 metric: 1 - SS_res / SS_tot\n",
    "        \"\"\"\n",
    "        ss_res =  K.sum(K.square(y_true - y_pred)) \n",
    "        ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "        # avoid division by zero\n",
    "        return 1 - ss_res/(ss_tot + K.epsilon())\n",
    "    def neg_r2_loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Loss function to *maximize* R^2 by minimizing its negative.\n",
    "        \"\"\"\n",
    "        return -r2_keras(y_true, y_pred)\n",
    "    if loss_name == \"mse\":\n",
    "        loss_lstm = MeanSquaredError()\n",
    "    elif loss_name == \"r2\":\n",
    "        loss_lstm = neg_r2_loss\n",
    "    else:\n",
    "        # handles quantile_1,3,5,7,9 etc.\n",
    "        q = int(loss_name.split(\"_\")[1]) / 10.0\n",
    "        loss_lstm = quantile_loss(q)\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_lstm,\n",
    "        metrics=[MeanSquaredError(name='mse'),\n",
    "                RootMeanSquaredError(name='rmse')]\n",
    "    )\n",
    "    # Callbacks\n",
    "    class TimeLimit(Callback):\n",
    "        def __init__(self, max_seconds): super().__init__(); self.max_seconds = max_seconds\n",
    "        def on_train_begin(self, logs=None): self.t0 = time.time()\n",
    "        def on_batch_end(self, batch, logs=None): (time.time() - self.t0 > self.max_seconds) and setattr(self.model, 'stop_training', True)\n",
    "    es = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "    rlrop = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2)\n",
    "    time_cb = TimeLimit(3600) \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_holdout, y_holdout),\n",
    "        callbacks=[es, rlrop, time_cb],\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    return min(history.history['val_rmse']), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f43e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm, trange\n",
    "import shap\n",
    "\n",
    "class TreeTimeLSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 lstm_units,\n",
    "                 num_layers,\n",
    "                 dropout,\n",
    "                 recurrent_dropout,\n",
    "                 bidirectional,\n",
    "                 l1=0.0,\n",
    "                 l2=0.0,\n",
    "                 use_conv1d=False,\n",
    "                 conv_kernel=3,\n",
    "                 noise_std=0.0,\n",
    "                 inter_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.use_conv1d = use_conv1d\n",
    "        self.noise_std = noise_std\n",
    "        self.inter_dropout = inter_dropout\n",
    "\n",
    "        if use_conv1d:\n",
    "            self.conv1d = nn.Conv1d(\n",
    "                in_channels=input_size,\n",
    "                out_channels=lstm_units,\n",
    "                kernel_size=conv_kernel,\n",
    "                padding=conv_kernel//2\n",
    "            )\n",
    "            input_size = lstm_units\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=lstm_units,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(inter_dropout) if inter_dropout > 0 else None\n",
    "        self.output = nn.Linear(\n",
    "            lstm_units * (2 if bidirectional else 1),\n",
    "            1\n",
    "        )\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.noise_std > 0:\n",
    "            x = x + torch.randn_like(x) * self.noise_std\n",
    "        if self.use_conv1d:\n",
    "            x = x.transpose(1, 2)\n",
    "            x = self.conv1d(x)\n",
    "            x = x.transpose(1, 2)\n",
    "        out, _ = self.lstm(x)\n",
    "        out_last = out[:, -1, :]\n",
    "        if self.dropout:\n",
    "            out_last = self.dropout(out_last)\n",
    "        return self.output(out_last)\n",
    "\n",
    "# Loss functions\n",
    "def quantile_loss(q):\n",
    "    def loss_fn(y_pred, y_true):\n",
    "        e = y_true - y_pred\n",
    "        return torch.mean(torch.max(q * e, (q - 1) * e))\n",
    "    return loss_fn\n",
    "\n",
    "def r2_metric(y_pred, y_true):\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / (ss_tot + 1e-6)\n",
    "\n",
    "def neg_r2_loss(y_pred, y_true):\n",
    "    return -r2_metric(y_pred, y_true)\n",
    "\n",
    "\n",
    "def run(params, train_Xtime, train_ytime, training_ratio=0.95, device='cpu'):\n",
    "    # Hyperparameters\n",
    "    lstm_units = params['TreeTime_lstm_units']\n",
    "    num_layers = params['TreeTime_lstm_num_layers']\n",
    "    dropout = params['TreeTime_lstm_dropout']\n",
    "    recurrent_dropout = params['TreeTime_lstm_recurrent_dropout']\n",
    "    learning_rate = params['TreeTime_lstm_learning_rate']\n",
    "    optimizer_name = params['TreeTime_lstm_optimizer']\n",
    "    bidirectional = params['TreeTime_lstm_bidirectional']\n",
    "    batch_size = params['TreeTime_lstm_batch_size']\n",
    "    epochs = params['TreeTime_lstm_epochs']\n",
    "    loss_name = params['TreeTime_lstm_loss']\n",
    "    l1 = params.get('TreeTime_lstm_l1', 0.0)\n",
    "    l2 = params.get('TreeTime_lstm_l2', 0.0)\n",
    "    inter_dropout = params.get('TreeTime_inter_dropout', 0.0)\n",
    "    noise_std = params.get('TreeTime_input_gaussian_noise', 0.0)\n",
    "    use_conv1d = params.get('TreeTime_lstm_conv1d', False)\n",
    "    conv_kernel = params.get('TreeTime_lstm_conv1d_kernel_size', 3)\n",
    "\n",
    "    # Data split\n",
    "    n_total = train_Xtime.shape[0]\n",
    "    split_at = int(n_total * training_ratio)\n",
    "    X_train, y_train = train_Xtime[:split_at], train_ytime[:split_at]\n",
    "    X_val, y_val = train_Xtime[split_at:], train_ytime[split_at:]\n",
    "\n",
    "    train_ds = TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    val_ds = TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32),\n",
    "        torch.tensor(y_val, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    # Model\n",
    "    model = TreeTimeLSTM(\n",
    "        input_size=train_Xtime.shape[-1],\n",
    "        lstm_units=lstm_units,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        recurrent_dropout=recurrent_dropout,\n",
    "        bidirectional=bidirectional,\n",
    "        l1=l1,\n",
    "        l2=l2,\n",
    "        use_conv1d=use_conv1d,\n",
    "        conv_kernel=conv_kernel,\n",
    "        noise_std=noise_std,\n",
    "        inter_dropout=inter_dropout\n",
    "    ).to(device)\n",
    "\n",
    "    # Loss & optimizer\n",
    "    if loss_name == 'mse':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif loss_name == 'r2':\n",
    "        criterion = lambda pred, true: neg_r2_loss(pred, true)\n",
    "    else:\n",
    "        q = int(loss_name.split('_')[1]) / 10.0\n",
    "        criterion = quantile_loss(q)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=l2\n",
    "    )\n",
    "    if optimizer_name == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=l2\n",
    "        )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, factor=0.5, patience=2\n",
    "    )\n",
    "\n",
    "    best_rmse, wait = float('inf'), 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in trange(epochs, desc='Epochs'):\n",
    "        model.train()\n",
    "        sum_sq_error = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc='Training', leave=False):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(X_batch).squeeze()\n",
    "            # compute loss (with optional L1)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            if l1 > 0:\n",
    "                loss = loss + l1 * sum(p.abs().sum() for p in model.parameters())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # accumulate squared error for RMSE\n",
    "            # note: detach so it doesn't track grads\n",
    "            se = ((preds.detach() - y_batch) ** 2).sum().item()\n",
    "            sum_sq_error += se\n",
    "            total_samples += y_batch.numel()\n",
    "\n",
    "            if time.time() - start_time > 3600:\n",
    "                break\n",
    "\n",
    "        train_rmse = (sum_sq_error / total_samples) ** 0.5\n",
    "\n",
    "        # validation as before\n",
    "        model.eval()\n",
    "        val_rmses = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in tqdm(val_loader, desc='Validation', leave=False):\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                preds = model(X_batch).squeeze()\n",
    "                mse = nn.MSELoss()(preds, y_batch)\n",
    "                val_rmses.append(torch.sqrt(mse).item())\n",
    "        val_rmse = sum(val_rmses) / len(val_rmses)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} — \"\n",
    "            f\"Train RMSE: {train_rmse:.4f} — \"\n",
    "            f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "        scheduler.step(val_rmse)\n",
    "        \n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse, wait = val_rmse, 0\n",
    "            best_state = model.state_dict()\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= 3:\n",
    "                break\n",
    "        if time.time() - start_time > 3600:\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return best_rmse, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec092cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 1/2 [01:05<01:05, 65.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 — Train RMSE: 0.1182 — Validation RMSE: 0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 2/2 [02:08<00:00, 64.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 — Train RMSE: 0.0978 — Validation RMSE: 0.0919\n",
      "Validation RMSE: 0.0919\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "val_rmse, model = run(params, train_Xtime, train_ytime, training_ratio=0.9, device=device)\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "30e3be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.0983\n",
      "Mean all prediction: 0.5034\n",
      "Mean above prediction: 0.5712\n",
      "Mean below prediction: 0.4662\n",
      "True values above zero: 0.0500\n",
      "True values below zero: 0.0233\n"
     ]
    }
   ],
   "source": [
    "X_new = np.random.randn(5, train_Xtime.shape[1], train_Xtime.shape[2])\n",
    "\n",
    "# Convert to torch tensor and send to device\n",
    "n = 100000\n",
    "X_tensor = torch.tensor(train_Xtime[-n:], dtype=torch.float32).to(device)\n",
    "\n",
    "# Put model into eval mode and disable grad\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_tensor)        # (N, 1) tensor\n",
    "    preds = preds[:,0]      # (N,) tensor\n",
    "\n",
    "# Bring back to CPU NumPy array if you like\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "true_val = train_ytime[-n:]\n",
    "\n",
    "rsme_err = np.sqrt(np.mean((preds - train_ytime[-n:])**2))\n",
    "q = 0.95\n",
    "mask_pred_above = preds >= np.quantile(preds, q)\n",
    "mask_pred_below = preds <= np.quantile(preds, 1-q)\n",
    "print(f\"Mean error: {rsme_err:.4f}\")\n",
    "print(f\"Mean all prediction: {np.mean(true_val):.4f}\")\n",
    "print(f\"Mean above prediction: {np.mean(true_val[mask_pred_above]):.4f}\")\n",
    "print(f\"Mean below prediction: {np.mean(true_val[mask_pred_below]):.4f}\")\n",
    "print(f\"True values above zero: {np.sum(mask_pred_above)/len(mask_pred_above):.4f}\")\n",
    "print(f\"True values below zero: {np.sum(true_val[mask_pred_below])/len(mask_pred_below):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2deea398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([239, 239, 239, 239,  92, 147,  69,  23, 147,  92, 147,  92, 147,\n",
       "        10,  82, 147, 239,  92,  77, 162,  77,  70,   2,  67, 170,  69,\n",
       "       100,  70, 169,  70, 391,  81, 158,  81, 239, 158,  81, 158,  81,\n",
       "       158,  97, 142,  17,  64,   6,  10, 142,  17,  64,   6,  10, 142,\n",
       "        17,  70,  10, 142,  97, 239, 142,  97, 620, 239, 256, 222,  97,\n",
       "       142,  97, 239, 142,  97, 239, 231,   8, 231,   8, 190,  49, 229,\n",
       "        10, 190,  39,  10, 159,  31,  39,  10, 159,  31,  39,   2,   8,\n",
       "        59,  83,  17,  31,  39,   2,   8,  59, 100,  70,   2,   8,  59,\n",
       "       100,  70,  10,  59, 100,  66,  10,  59,  99, 135,  99, 135,  99,\n",
       "       135,  99, 132, 114, 153,  25,  89,  45, 267,  45,  65, 202,   6,\n",
       "        39,  27,  38, 199,   3,  45,  65,  56, 143,   3,   6,  39,  27,\n",
       "        38,  23,  33,  17, 126,   3,  45,  65,  23,  33, 143,   3,  45,\n",
       "        65,  23,  33, 143,   3, 110,  56, 146, 110,  56, 143, 169, 143,\n",
       "        48, 264,  48, 121, 772, 307,   5,  49, 258,   5,   4,  66, 126,\n",
       "       186, 237,  54, 147, 111,   5,  49, 147, 111,   5,   4,  66,  38,\n",
       "        88, 111,  48,  65])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(np.where(mask_pred_above)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0099a8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m792s\u001b[0m 5s/step - loss: 0.1599 - mse: 0.0145 - rmse: 0.1049 - val_loss: 0.1010 - val_mse: 9.3428e-04 - val_rmse: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m 55/148\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m 5s/step - loss: 0.0960 - mse: 6.3655e-04 - rmse: 0.0251"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m val_rmse, model = \u001b[43mrun_tf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Xtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ytime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mrun_tf\u001b[39m\u001b[34m(params, train_Xtime, train_ytime, training_ratio)\u001b[39m\n\u001b[32m    107\u001b[39m time_cb = TimeLimit(\u001b[32m3600\u001b[39m) \n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrlrop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(history.history[\u001b[33m'\u001b[39m\u001b[33mval_rmse\u001b[39m\u001b[33m'\u001b[39m]), model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "val_rmse, model = run_tf(params, train_Xtime, train_ytime, training_ratio=0.9)\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abd22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def explain_grad_input(model, test_data, device='cpu'):\n",
    "    \"\"\"\n",
    "    Compute feature importances via Gradient x Input for an LSTM model.\n",
    "\n",
    "    model: trained TreeTimeLSTM\n",
    "    test_data: numpy array (N, seq, features)\n",
    "    \"\"\"\n",
    "    model.to(device).eval()\n",
    "    inputs = torch.tensor(test_data, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    \n",
    "    # forward pass\n",
    "    outputs = model(inputs).squeeze()               # (N,)\n",
    "    \n",
    "    # backpropagate to get ∂y/∂x\n",
    "    grads = torch.autograd.grad(\n",
    "        outputs,\n",
    "        inputs,\n",
    "        grad_outputs=torch.ones_like(outputs),\n",
    "        retain_graph=False,\n",
    "        create_graph=False\n",
    "    )[0]                                             # shape: (N, seq, features)\n",
    "    \n",
    "    # gradient × input\n",
    "    attributions = grads * inputs                   # elementwise\n",
    "    # aggregate over sequence dimension to get per-feature importance\n",
    "    feature_importance = attributions.abs().mean(dim=1)  # shape: (N, features)\n",
    "    \n",
    "    return feature_importance.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9622148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importances shape: (999, 5)\n",
      "MathFeature_TradedPrice: 0.0000\n",
      "MathFeature_TradedPrice_sp0: 0.0000\n",
      "MathFeature_TradedPrice_sp1: 0.0000\n",
      "MathFeature_Return: 0.0000\n",
      "MathFeature_PriceAdjustment: 0.0000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m importances_mean = importances.mean(axis=\u001b[32m0\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(timenames):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mimportances_mean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m*\u001b[32m1e5\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "# usage\n",
    "test_samples = train_Xtime[-1000:-1]\n",
    "importances = explain_grad_input(model, test_samples)\n",
    "print(\"Importances shape:\", importances.shape)  # -> (5, n_features)\n",
    "\n",
    "importances_mean = importances.mean(axis=0)\n",
    "\n",
    "for i, name in enumerate(timenames):\n",
    "    print(f\"{name}: {importances_mean[i]*1e5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ce653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on sample: 0.0234\n",
      "Mean on masked : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimer\\AppData\\Local\\Temp\\ipykernel_14096\\570207082.py:23: RuntimeWarning: Mean of empty slice.\n",
      "  mean_true_masked = (ytree_true[mask]).mean()\n",
      "c:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device).eval()\n",
    "\n",
    "# pick k random indices\n",
    "idx = random.sample(range(len(train_Xtime)), 200)\n",
    "Xtime_sample = train_Xtime[-1000:-1]\n",
    "ytime_true  = train_ytime[-1000:-1].reshape(-1)\n",
    "ytree_true = train_ytree[-1000:-1].reshape(-1)\n",
    "\n",
    "# prepare tensor\n",
    "X_tensor = torch.tensor(Xtime_sample, dtype=torch.float32)\n",
    "\n",
    "# tensor on correct device\n",
    "X_tensor = torch.from_numpy(Xtime_sample).float().to(device)\n",
    "with torch.no_grad():\n",
    "    preds = model(X_tensor).squeeze().cpu().numpy()\n",
    "    \n",
    "preds_tree = (preds-0.5)/5 +1.0\n",
    "rmse = np.sqrt(((ytree_true - preds_tree)**2).mean())\n",
    "\n",
    "print(f\"RMSE on sample: {rmse:.4f}\")\n",
    "\n",
    "mask = preds_tree > np.quantile(preds_tree, 0.8)\n",
    "mean_true_masked = (ytree_true[mask]).mean()\n",
    "print(f\"Mean on masked : {mean_true_masked:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6636c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def run_gpt(params,\n",
    "        train_Xtime_np,\n",
    "        train_ytime_np,\n",
    "        training_ratio=0.95,\n",
    "        subset_ratio=0.1,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Train an LSTM on the first `training_ratio` of (train_Xtime, train_ytime),\n",
    "    then select the top `subset_ratio` fraction of samples by predicted score\n",
    "    on both train and held-out validation, and report their actual means.\n",
    "    \"\"\"\n",
    "    # -- split train / val by time order --\n",
    "    train_Xtime = torch.from_numpy(train_Xtime_np).float()\n",
    "    train_ytime = torch.from_numpy(train_ytime_np).float()\n",
    "    N = train_Xtime.shape[0]\n",
    "    split = int(N * training_ratio)\n",
    "    X_train = train_Xtime[:split].to(device)\n",
    "    y_train = train_ytime[:split].to(device)\n",
    "    X_val   = train_Xtime[split:].to(device)\n",
    "    y_val   = train_ytime[split:].to(device)\n",
    "\n",
    "    # -- model setup --\n",
    "    D = X_train.size(-1)\n",
    "    H = params.get('hidden_size', 64)\n",
    "    model = nn.Sequential(\n",
    "        nn.LSTM(input_size=D, hidden_size=H, batch_first=True),\n",
    "        nn.Flatten(start_dim=0, end_dim=1),                     # (h, _) → (N, H)\n",
    "        nn.Linear(H, 1)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params.get('lr', 1e-3))\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # -- training loop --\n",
    "    batch_size = params.get('batch_size', 512)\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(params.get('epochs', 10)):\n",
    "        model.train()\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds, _ = model[0](xb)        # unpack LSTM\n",
    "            last = preds[:, -1, :]\n",
    "            out = model[2](last)\n",
    "            loss = loss_fn(out.squeeze(), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # -- scoring and subset selection --\n",
    "    device = torch.device('cpu')\n",
    "    # move model parts\n",
    "    model0 = model[0].to(device)\n",
    "    model2 = model[2].to(device)\n",
    "\n",
    "    # move your data\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_val   = X_val.to(device)\n",
    "    y_val   = y_val.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # train\n",
    "        preds_tr, _ = model0(X_train)\n",
    "        scores_tr = model2(preds_tr[:, -1, :]).squeeze()\n",
    "        k_tr = max(1, int(len(scores_tr) * subset_ratio))\n",
    "        top_tr = torch.topk(scores_tr, k_tr).indices\n",
    "        mean_tr_subset = y_train[top_tr].mean().item()\n",
    "        mean_tr_all    = y_train.mean().item()\n",
    "\n",
    "        # validation\n",
    "        preds_val, _ = model0(X_val)\n",
    "        scores_val = model2(preds_val[:, -1, :]).squeeze()\n",
    "        k_val = max(1, int(len(scores_val) * subset_ratio))\n",
    "        top_val = torch.topk(scores_val, k_val).indices\n",
    "        mean_val_subset = y_val[top_val].mean().item()\n",
    "        mean_val_all    = y_val.mean().item()\n",
    "\n",
    "    # -- results --\n",
    "    torch.cuda.empty_cache()\n",
    "    return {\n",
    "        'mean_train_all': mean_tr_all,\n",
    "        'mean_train_subset': mean_tr_subset,\n",
    "        'mean_val_all': mean_val_all,\n",
    "        'mean_val_subset': mean_val_subset,\n",
    "        'train_subset_idx': top_tr.cpu().numpy(),\n",
    "        'val_subset_idx': top_val.cpu().numpy(),\n",
    "        'model': model\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "959f459c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())      # should print True\n",
    "print(torch.cuda.get_device_name(0))  # your GPU name\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "86a5a283",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# set your LSTM params\u001b[39;00m\n\u001b[32m      2\u001b[39m params = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m128\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1e-3\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m128\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m50\u001b[39m\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m results = \u001b[43mrun_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Xtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ytime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m              \u001b[49m\u001b[43mtraining_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# inspect outcome\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean y (all train):   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mmean_train_all\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mrun_gpt\u001b[39m\u001b[34m(params, train_Xtime_np, train_ytime_np, training_ratio, subset_ratio, device)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(params.get(\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m10\u001b[39m)):\n\u001b[32m     43\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# unpack LSTM\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# set your LSTM params\n",
    "params = {\n",
    "    'hidden_size': 128,\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "results = run_gpt(params, train_Xtime, train_ytime,\n",
    "              training_ratio=0.90, subset_ratio=0.2)\n",
    "\n",
    "# inspect outcome\n",
    "print(f\"Mean y (all train):   {results['mean_train_all']:.3f}\")\n",
    "print(f\"Mean y (top 10% train):{results['mean_train_subset']:.3f}\")\n",
    "print(f\"Mean y (all val):     {results['mean_val_all']:.3f}\")\n",
    "print(f\"Mean y (top 10% val): {results['mean_val_subset']:.3f}\")\n",
    "\n",
    "# indices of selected samples\n",
    "print(\"Selected train indices:\", results['train_subset_idx'])\n",
    "print(\"Selected val   indices:\", results['val_subset_idx'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44275dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = results['val_subset_idx']\n",
    "ddiff = np.diff(np.sort(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({\n",
    "    \"TreeTime_lstm_units\": 16,\n",
    "    \"TreeTime_lstm_num_layers\": 4,\n",
    "    \"TreeTime_lstm_learning_rate\": 0.002,\n",
    "    \"TreeTime_lstm_conv1d\": True,\n",
    "    \"TreeTime_lstm_batch_size\": 2**11,\n",
    "    \"TreeTime_lstm_epochs\": 2,\n",
    "    \"TreeTime_lstm_dropout\": 0.00,\n",
    "    \"TreeTime_inter_dropout\": 0.00,\n",
    "    \"TreeTime_input_gaussian_noise\": 0.0,\n",
    "    \"TreeTime_lstm_loss\": \"mse\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd8141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Epoch 1/4\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8s/step - loss: 0.3672 - mse: 0.2512 - rmse: 0.4989 - val_loss: 0.1738 - val_mse: 0.0611 - val_rmse: 0.2472 - learning_rate: 0.0010\n",
      "Epoch 2/4\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8s/step - loss: 0.1861 - mse: 0.0744 - rmse: 0.2705 - val_loss: 0.1918 - val_mse: 0.0798 - val_rmse: 0.2825 - learning_rate: 0.0010\n",
      "Epoch 3/4\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8s/step - loss: 0.1859 - mse: 0.0738 - rmse: 0.2723 - val_loss: 0.1674 - val_mse: 0.0564 - val_rmse: 0.2375 - learning_rate: 0.0010\n",
      "Epoch 4/4\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8s/step - loss: 0.1759 - mse: 0.0650 - rmse: 0.2548 - val_loss: 0.1640 - val_mse: 0.0540 - val_rmse: 0.2323 - learning_rate: 0.0010\n",
      "Validation RMSE: 0.2323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step\n",
      "Train RMSE: 0.2496\n",
      "Sqrt Variance: 0.0849\n",
      "mean y time: 0.5315\n",
      "pred Quantile 0.5: 0.5364\n",
      "pred Quantile 0.8: 0.5324\n",
      "Mask size: 0.7999969742356162\n",
      "Iteration 2/5\n",
      "Epoch 1/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9s/step - loss: 0.3494 - mse: 0.2350 - rmse: 0.4811 - val_loss: 0.2258 - val_mse: 0.1128 - val_rmse: 0.3358 - learning_rate: 0.0010\n",
      "Epoch 2/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9s/step - loss: 0.2132 - mse: 0.0999 - rmse: 0.3163 - val_loss: 0.1762 - val_mse: 0.0639 - val_rmse: 0.2527 - learning_rate: 0.0010\n",
      "Epoch 3/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9s/step - loss: 0.1903 - mse: 0.0784 - rmse: 0.2790 - val_loss: 0.1816 - val_mse: 0.0700 - val_rmse: 0.2647 - learning_rate: 0.0010\n",
      "Epoch 4/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8s/step - loss: 0.1826 - mse: 0.0711 - rmse: 0.2668 - val_loss: 0.1573 - val_mse: 0.0466 - val_rmse: 0.2158 - learning_rate: 0.0010\n",
      "Validation RMSE: 0.2158\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\n",
      "Train RMSE: 0.2396\n",
      "Sqrt Variance: 0.0589\n",
      "mean y time: 0.5339\n",
      "pred Quantile 0.5: 0.5376\n",
      "pred Quantile 0.8: 0.5335\n",
      "Mask size: 0.6399945536241093\n",
      "Iteration 3/5\n",
      "Epoch 1/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6s/step - loss: 0.2755 - mse: 0.1581 - rmse: 0.4014 - val_loss: 0.1706 - val_mse: 0.0576 - val_rmse: 0.2401 - learning_rate: 0.0010\n",
      "Epoch 2/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6s/step - loss: 0.1778 - mse: 0.0658 - rmse: 0.2547 - val_loss: 0.1847 - val_mse: 0.0726 - val_rmse: 0.2694 - learning_rate: 0.0010\n",
      "Epoch 3/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6s/step - loss: 0.1875 - mse: 0.0739 - rmse: 0.2748 - val_loss: 0.1574 - val_mse: 0.0463 - val_rmse: 0.2152 - learning_rate: 0.0010\n",
      "Epoch 4/4\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6s/step - loss: 0.1669 - mse: 0.0562 - rmse: 0.2360 - val_loss: 0.1651 - val_mse: 0.0550 - val_rmse: 0.2345 - learning_rate: 0.0010\n",
      "Validation RMSE: 0.2152\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B1402107C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B1402107C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n",
      "Train RMSE: 0.2591\n",
      "Sqrt Variance: 0.0565\n",
      "mean y time: 0.5351\n",
      "pred Quantile 0.5: 0.5372\n",
      "pred Quantile 0.8: 0.5293\n",
      "Mask size: 0.51198959137052\n",
      "Iteration 4/5\n",
      "Epoch 1/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step - loss: 0.3823 - mse: 0.2622 - rmse: 0.5157 - val_loss: 0.2499 - val_mse: 0.1367 - val_rmse: 0.3698 - learning_rate: 0.0010\n",
      "Epoch 2/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8s/step - loss: 0.2424 - mse: 0.1283 - rmse: 0.3593 - val_loss: 0.1603 - val_mse: 0.0475 - val_rmse: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 3/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8s/step - loss: 0.1778 - mse: 0.0665 - rmse: 0.2536 - val_loss: 0.1991 - val_mse: 0.0867 - val_rmse: 0.2944 - learning_rate: 0.0010\n",
      "Epoch 4/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8s/step - loss: 0.2025 - mse: 0.0906 - rmse: 0.3002 - val_loss: 0.1659 - val_mse: 0.0539 - val_rmse: 0.2322 - learning_rate: 0.0010\n",
      "Validation RMSE: 0.2178\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n",
      "Train RMSE: 0.3139\n",
      "Sqrt Variance: 0.0228\n",
      "mean y time: 0.5363\n",
      "pred Quantile 0.5: 0.5374\n",
      "pred Quantile 0.8: 0.5244\n",
      "Mask size: 0.4095825958032648\n",
      "Iteration 5/5\n",
      "Epoch 1/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - loss: 0.5735 - mse: 0.4086 - rmse: 0.6766 - val_loss: 0.2706 - val_mse: 0.1576 - val_rmse: 0.3970 - learning_rate: 0.0010\n",
      "Epoch 2/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.2790 - mse: 0.1604 - rmse: 0.4073 - val_loss: 0.1807 - val_mse: 0.0679 - val_rmse: 0.2605 - learning_rate: 0.0010\n",
      "Epoch 3/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.1936 - mse: 0.0800 - rmse: 0.2843 - val_loss: 0.1795 - val_mse: 0.0669 - val_rmse: 0.2587 - learning_rate: 0.0010\n",
      "Epoch 4/4\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.1978 - mse: 0.0919 - rmse: 0.2916 - val_loss: 0.1863 - val_mse: 0.0740 - val_rmse: 0.2721 - learning_rate: 0.0010\n",
      "Validation RMSE: 0.2587\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n",
      "Train RMSE: 0.2879\n",
      "Sqrt Variance: 0.0215\n",
      "mean y time: 0.5370\n",
      "pred Quantile 0.5: 0.5298\n",
      "pred Quantile 0.8: 0.5255\n",
      "Mask size: 0.3276600251138444\n"
     ]
    }
   ],
   "source": [
    "q = 0.2\n",
    "itermax = 5\n",
    "\n",
    "mask = np.ones(train_Xtime.shape[0], dtype=bool)\n",
    "for i in range(itermax):\n",
    "    print(f\"Iteration {i+1}/{itermax}\")\n",
    "    \n",
    "    val_rmse, model = run_torch(params, train_Xtime=train_Xtime[mask], train_ytime=train_ytime[mask], training_ratio=0.9)\n",
    "    print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "    \n",
    "    # Update mask based on validation RMSE\n",
    "    y_train_pred = model.predict(train_Xtime[mask], batch_size=params['TreeTime_lstm_batch_size'])[:,0]\n",
    "    rsme_train = np.sqrt(np.mean((y_train_pred - train_ytime[mask]) ** 2))\n",
    "    print(f\"Train RMSE: {rsme_train:.4f}\")\n",
    "    print(f\"Sqrt Variance: {np.sqrt(np.var(y_train_pred)):.4f}\")\n",
    "    print(f\"mean y time: {np.mean(train_ytime[mask]):.4f}\")\n",
    "    print(f\"pred Quantile 0.5: {np.mean(train_ytime[mask][y_train_pred > np.quantile(y_train_pred, 0.5)]):.4f}\")\n",
    "    print(f\"pred Quantile 0.8: {np.mean(train_ytime[mask][y_train_pred > np.quantile(y_train_pred, 0.8)]):.4f}\")\n",
    "    \n",
    "    mask_loop = (y_train_pred > np.quantile(y_train_pred, q))\n",
    "    prev_count = mask.sum()\n",
    "    mask[mask] = mask_loop\n",
    "    new_count = mask.sum()\n",
    "    print(f\"Mask size: {new_count/train_Xtime.shape[0]}\")\n",
    "    if new_count == prev_count:\n",
    "        print(\"No change in mask, stopping early\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2613/2613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step\n",
      "Train RMSE: 0.1545\n",
      "Sqrt Variance: 0.0001\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(train_Xtime, batch_size=params['TreeTime_lstm_batch_size'])[:,0]\n",
    "rsme_train = np.sqrt(np.mean((y_train_pred - train_ytime) ** 2))\n",
    "print(f\"Train RMSE: {rsme_train:.4f}\")\n",
    "print(f\"Sqrt Variance: {np.sqrt(np.var(y_train_pred)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbaaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean y time: 0.5085\n",
      "pred Quantile 0.5: 0.5106\n",
      "pred Quantile 0.8: 0.5124\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean y time: {np.mean(train_ytime):.4f}\")\n",
    "print(f\"pred Quantile 0.5: {np.mean(train_ytime[y_train_pred > np.quantile(y_train_pred, 0.5)]):.4f}\")\n",
    "print(f\"pred Quantile 0.8: {np.mean(train_ytime[y_train_pred > np.quantile(y_train_pred, 0.8)]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5264131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Test RMSE: 0.1250\n",
      "Sqrt Variance: 0.0001\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(test_Xtime, batch_size=params['TreeTime_lstm_batch_size'])[:,0]\n",
    "rsme_test = np.sqrt(np.mean((y_test_pred - test_ytime) ** 2))\n",
    "print(f\"Test RMSE: {rsme_test:.4f}\")\n",
    "print(f\"Sqrt Variance: {np.sqrt(np.var(y_test_pred)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "zz = 0\n",
    "zzz = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial: optuna.Trial):\n",
    "    # sample hyperparameters\n",
    "    optparams = params.copy()\n",
    "    optparams.update({\n",
    "        \"TreeTime_lstm_units\": trial.suggest_categorical(\"units\", [64, 128, 256]),\n",
    "        \"TreeTime_lstm_num_layers\": trial.suggest_int(\"num_layers\", 3, 8),\n",
    "        \"TreeTime_lstm_learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 5e-2),\n",
    "        \"TreeTime_lstm_conv1d\": trial.suggest_categorical(\"use_conv1d\", [False, True]),\n",
    "        \"TreeTime_lstm_batch_size\": trial.suggest_categorical(\"batch_size\", [2**12, 2**13, 2**14]),\n",
    "    })\n",
    "    # run and report validation RMSE\n",
    "    val_rmse = run_torch(optparams)\n",
    "    trial.report(val_rmse, step=0)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "    return val_rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "study.optimize(objective, timeout=60*60*8)\n",
    "\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
