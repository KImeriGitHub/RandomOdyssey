{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3b363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 22:31:40,700 - This will print to the notebook's output cell\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project directory\n",
    "project_dir = os.path.abspath(\"..\")\n",
    "\n",
    "# Append the project directory to sys.path\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "    \n",
    "from src.predictionModule.LoadupSamples import LoadupSamples\n",
    "from src.predictionModule.FilterSamples import FilterSamples\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "formatted_date = datetime.datetime.now().strftime(\"%d%b%y_%H%M\").lower()\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter(fmt=\"%(asctime)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(handler)\n",
    "else:\n",
    "    logger.handlers[:] = [handler]\n",
    "\n",
    "#Output File handler\n",
    "formatted_str = f\"notebook-lstm-optuna-{formatted_date}\"\n",
    "file_handler = logging.FileHandler(f\"{formatted_str}.log\", mode=\"w\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Usage\n",
    "logger.info(\"This will print to the notebook's output cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb954e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"idxAfterPrediction\": 5,\n",
    "    'timesteps': 60,\n",
    "    'target_option': 'last',\n",
    "    \n",
    "    \"TreeTime_lstm_units\": 32,\n",
    "    \"TreeTime_lstm_num_layers\": 3,\n",
    "    \"TreeTime_lstm_dropout\": 0.00001,\n",
    "    \"TreeTime_lstm_recurrent_dropout\": 0.00001,\n",
    "    \"TreeTime_lstm_learning_rate\": 0.001,\n",
    "    \"TreeTime_lstm_optimizer\": \"adam\",\n",
    "    \"TreeTime_lstm_bidirectional\": True,\n",
    "    \"TreeTime_lstm_batch_size\": 2**12,\n",
    "    \"TreeTime_lstm_epochs\": 20,\n",
    "    \"TreeTime_lstm_l1\": 0.00001,\n",
    "    \"TreeTime_lstm_l2\": 0.00001,\n",
    "    \"TreeTime_inter_dropout\": 0.00001,\n",
    "    \"TreeTime_input_gaussian_noise\": 0.00001,\n",
    "    \"TreeTime_lstm_conv1d\": True,\n",
    "    \"TreeTime_lstm_conv1d_kernel_size\": 3,\n",
    "    \"TreeTime_lstm_loss\": \"mse\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c306cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_group = \"group_snp500_finanTo2011\"\n",
    "\n",
    "eval_dates = sorted([\n",
    "    datetime.date(2025,  2,  1) - datetime.timedelta(days=i*60 + random.randint(-10,10)) \n",
    "    for i in range(1)\n",
    "])\n",
    "\n",
    "years_back = 9\n",
    "start_Dates = [eval_date - datetime.timedelta(days=365 * years_back) for eval_date in eval_dates]\n",
    "start_Dates = [datetime.date(year=start_date.year, month=1, day=1) for start_date in start_Dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8289692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimer\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm, trange\n",
    "import shap\n",
    "\n",
    "class TreeTimeLSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 lstm_units,\n",
    "                 num_layers,\n",
    "                 dropout,\n",
    "                 recurrent_dropout,\n",
    "                 bidirectional,\n",
    "                 l1=0.0,\n",
    "                 l2=0.0,\n",
    "                 use_conv1d=False,\n",
    "                 conv_kernel=3,\n",
    "                 noise_std=0.0,\n",
    "                 inter_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.use_conv1d = use_conv1d\n",
    "        self.noise_std = noise_std\n",
    "        self.inter_dropout = inter_dropout\n",
    "\n",
    "        if use_conv1d:\n",
    "            self.conv1d = nn.Conv1d(\n",
    "                in_channels=input_size,\n",
    "                out_channels=lstm_units,\n",
    "                kernel_size=conv_kernel,\n",
    "                padding=conv_kernel//2\n",
    "            )\n",
    "            input_size = lstm_units\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=lstm_units,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(inter_dropout) if inter_dropout > 0 else None\n",
    "        self.output = nn.Linear(\n",
    "            lstm_units * (2 if bidirectional else 1),\n",
    "            1\n",
    "        )\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.noise_std > 0:\n",
    "            x = x + torch.randn_like(x) * self.noise_std\n",
    "        if self.use_conv1d:\n",
    "            x = x.transpose(1, 2)\n",
    "            x = self.conv1d(x)\n",
    "            x = x.transpose(1, 2)\n",
    "        out, _ = self.lstm(x)\n",
    "        out_last = out[:, -1, :]\n",
    "        if self.dropout:\n",
    "            out_last = self.dropout(out_last)\n",
    "        return self.output(out_last)\n",
    "\n",
    "# Loss functions\n",
    "def quantile_loss(q):\n",
    "    def loss_fn(y_pred, y_true):\n",
    "        e = y_true - y_pred\n",
    "        return torch.mean(torch.max(q * e, (q - 1) * e))\n",
    "    return loss_fn\n",
    "\n",
    "def r2_metric(y_pred, y_true):\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / (ss_tot + 1e-6)\n",
    "\n",
    "def neg_r2_loss(y_pred, y_true):\n",
    "    return -r2_metric(y_pred, y_true)\n",
    "\n",
    "\n",
    "def run(params, train_Xtime, train_ytime, training_ratio=0.95, device='cpu'):\n",
    "    # Hyperparameters\n",
    "    lstm_units = params['TreeTime_lstm_units']\n",
    "    num_layers = params['TreeTime_lstm_num_layers']\n",
    "    dropout = params['TreeTime_lstm_dropout']\n",
    "    recurrent_dropout = params['TreeTime_lstm_recurrent_dropout']\n",
    "    learning_rate = params['TreeTime_lstm_learning_rate']\n",
    "    optimizer_name = params['TreeTime_lstm_optimizer']\n",
    "    bidirectional = params['TreeTime_lstm_bidirectional']\n",
    "    batch_size = params['TreeTime_lstm_batch_size']\n",
    "    epochs = params['TreeTime_lstm_epochs']\n",
    "    loss_name = params['TreeTime_lstm_loss']\n",
    "    l1 = params.get('TreeTime_lstm_l1', 0.0)\n",
    "    l2 = params.get('TreeTime_lstm_l2', 0.0)\n",
    "    inter_dropout = params.get('TreeTime_inter_dropout', 0.0)\n",
    "    noise_std = params.get('TreeTime_input_gaussian_noise', 0.0)\n",
    "    use_conv1d = params.get('TreeTime_lstm_conv1d', False)\n",
    "    conv_kernel = params.get('TreeTime_lstm_conv1d_kernel_size', 3)\n",
    "\n",
    "    # Data split\n",
    "    n_total = train_Xtime.shape[0]\n",
    "    split_at = int(n_total * training_ratio)\n",
    "    X_train, y_train = train_Xtime[:split_at], train_ytime[:split_at]\n",
    "    X_val, y_val = train_Xtime[split_at:], train_ytime[split_at:]\n",
    "\n",
    "    train_ds = TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    val_ds = TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32),\n",
    "        torch.tensor(y_val, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    # Model\n",
    "    model = TreeTimeLSTM(\n",
    "        input_size=train_Xtime.shape[-1],\n",
    "        lstm_units=lstm_units,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        recurrent_dropout=recurrent_dropout,\n",
    "        bidirectional=bidirectional,\n",
    "        l1=l1,\n",
    "        l2=l2,\n",
    "        use_conv1d=use_conv1d,\n",
    "        conv_kernel=conv_kernel,\n",
    "        noise_std=noise_std,\n",
    "        inter_dropout=inter_dropout\n",
    "    ).to(device)\n",
    "\n",
    "    # Loss & optimizer\n",
    "    if loss_name == 'mse':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif loss_name == 'r2':\n",
    "        criterion = lambda pred, true: neg_r2_loss(pred, true)\n",
    "    else:\n",
    "        q = int(loss_name.split('_')[1]) / 10.0\n",
    "        criterion = quantile_loss(q)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=l2\n",
    "    )\n",
    "    if optimizer_name == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=l2\n",
    "        )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, factor=0.5, patience=2\n",
    "    )\n",
    "\n",
    "    best_rmse, wait = float('inf'), 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in trange(epochs, desc='Epochs'):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in tqdm(\n",
    "            train_loader, desc='Training', leave=False\n",
    "        ):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch).squeeze()\n",
    "            loss = criterion(preds, y_batch)\n",
    "            if l1 > 0:\n",
    "                l1_penalty = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss += l1 * l1_penalty\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if time.time() - start_time > 3600:\n",
    "                break\n",
    "\n",
    "        model.eval()\n",
    "        val_rmses = []\n",
    "        for X_batch, y_batch in tqdm(\n",
    "            val_loader, desc='Validation', leave=False\n",
    "        ):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            preds = model(X_batch).squeeze()\n",
    "            mse = nn.MSELoss()(preds, y_batch)\n",
    "            val_rmses.append(torch.sqrt(mse).item())\n",
    "        val_rmse = sum(val_rmses) / len(val_rmses)\n",
    "        scheduler.step(val_rmse)\n",
    "\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse, wait = val_rmse, 0\n",
    "            best_state = model.state_dict()\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= 3:\n",
    "                break\n",
    "        if time.time() - start_time > 3600:\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return best_rmse, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ce5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorttest(model, train_Xtime, train_ytree, train_ytime, device='cpu'):\n",
    "    # Convert to torch tensor and send to device\n",
    "    n = 20000\n",
    "    X_tensor = torch.tensor(train_Xtime[-n:], dtype=torch.float32).to(device)\n",
    "\n",
    "    # Put model into eval mode and disable grad\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_tensor)        # (N, 1) tensor\n",
    "        preds = preds.squeeze(-1)      # (N,) tensor\n",
    "\n",
    "    # Bring back to CPU NumPy array if you like\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    true_val = train_ytree[-n:]\n",
    "\n",
    "    rsme_err = np.sqrt(np.mean((preds - train_ytime[-n:])**2))\n",
    "    q = 0.99\n",
    "    mask_pred_above = preds >= np.quantile(preds, q)\n",
    "    mask_pred_below = preds <= np.quantile(preds, 1-q)\n",
    "    logger.info(f\"  Mean error: {rsme_err:.4f}\")\n",
    "    logger.info(f\"  Mean all prediction: {np.mean(true_val):.4f}\")\n",
    "    logger.info(f\"  Mean above prediction: {np.mean(true_val[mask_pred_above]):.4f}\")\n",
    "    logger.info(f\"  Mean below prediction: {np.mean(true_val[mask_pred_below]):.4f}\")\n",
    "    logger.info(f\"  True values above zero: {np.sum(mask_pred_above)/len(mask_pred_above):.4f}\")\n",
    "    logger.info(f\"  True values below zero: {np.sum(true_val[mask_pred_below])/len(mask_pred_below):.4f}\")\n",
    "    \n",
    "    return np.mean(true_val[mask_pred_above]) + np.mean(true_val[mask_pred_below])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3912a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "split_f = 0.90  # Split fraction for train/test sets\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Suggest hyperparameters\n",
    "    opt_params = {\n",
    "        \"idxAfterPrediction\": trial.suggest_int(\"idxAfterPrediction\", 1, 5),\n",
    "        \"LoadupSamples_time_scaling_stretch\": trial.suggest_categorical(\"time_scaling_stretch\", [True, False]),\n",
    "        \"LoadupSamples_time_inc_factor\": trial.suggest_int(\"time_inc_factor\", 1, 20),\n",
    "    }\n",
    "    doFeatureReduce = trial.suggest_categorical(\"doFeatureReduce\", [True, False])\n",
    "\n",
    "    # Build and evaluate FilterSamples for each instance\n",
    "    scores_test = []\n",
    "    for i, date in enumerate(eval_dates):\n",
    "        ls = LoadupSamples(\n",
    "            train_start_date=start_Dates[i],\n",
    "            test_dates=[date],\n",
    "            group=stock_group,\n",
    "            params={**params, **opt_params}\n",
    "        )\n",
    "        try:\n",
    "            ls.load_samples(main_path = \"../src/featureAlchemy/bin/\")\n",
    "            train_Xtree = ls.train_Xtree\n",
    "            train_ytree = ls.train_ytree\n",
    "            train_Xtime = ls.train_Xtime\n",
    "            train_ytime = ls.train_ytime\n",
    "\n",
    "            timenames = ls.featureTimeNames\n",
    "            \n",
    "            if doFeatureReduce:\n",
    "                idx1 = np.where(timenames == \"MathFeature_TradedPrice\")[0][0]\n",
    "                idx2 = np.where(timenames == \"FeatureTA_High\")[0][0]\n",
    "                idx3 = np.where(timenames == \"FeatureTA_Low\")[0][0]\n",
    "                idx4 = np.where(timenames == \"FeatureTA_volume_obv\")[0][0]\n",
    "\n",
    "                train_Xtime = train_Xtime[:, :, [idx1, idx2, idx3, idx4]]\n",
    "            \n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            val_rmse, model = run(params, train_Xtime, train_ytime, training_ratio=split_f, device=device)\n",
    "            logger.info(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "            a = shorttest(model, train_Xtime, train_ytree, train_ytime, device=device)\n",
    "            \n",
    "            score = 1.0 if a is None or np.isnan(a) else a\n",
    "            \n",
    "        except ValueError:\n",
    "            score = 1.0\n",
    "            \n",
    "        scores_test.append(score)    \n",
    "        \n",
    "    logger.info(f\"Trial number {trial.number}\")\n",
    "    logger.info(f\"All scores (test) = {scores_test}\") \n",
    "    \n",
    "    fin_score = np.mean(np.log(scores_test))\n",
    "    logger.info(f\"Log mean of scores (test) {np.mean(np.log(scores_test))}\")\n",
    "    \n",
    "    return float(fin_score)\n",
    "\n",
    "optuna.logging.enable_propagation()\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "study.optimize(objective, timeout=60*60*1)\n",
    "\n",
    "logger.info(f\"Best parameters: {study.best_params}\")\n",
    "logger.info(f\"Best score: {study.best_value}\")\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "logger.info(\"\\nTrials DataFrame:\")\n",
    "logger.info(df.sort_values(\"value\").to_string())\n",
    "\n",
    "param_importances = optuna.importance.get_param_importances(study)\n",
    "logger.info(\"Parameter Importances:\")\n",
    "for key, value in param_importances.items():\n",
    "    logger.info(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9856fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f\"{formatted_str}.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
