{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3b363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-19 18:07:09,219 - This will print to the notebook's output cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project directory\n",
    "project_dir = os.path.abspath(\"..\")\n",
    "\n",
    "# Append the project directory to sys.path\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "    \n",
    "from src.predictionModule.LoadupSamples import LoadupSamples\n",
    "from src.predictionModule.MachineModels import MachineModels \n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import optuna\n",
    "\n",
    "import logging\n",
    "formatted_date = datetime.datetime.now().strftime(\"%d%b%y_%H%M\").lower()\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter(fmt=\"%(asctime)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(handler)\n",
    "else:\n",
    "    logger.handlers[:] = [handler]\n",
    "\n",
    "#Output File handler\n",
    "formatted_str = f\"notebook-lstm-optuna-{formatted_date}\"\n",
    "file_handler = logging.FileHandler(f\"{formatted_str}.log\", mode=\"w\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Usage\n",
    "logger.info(\"This will print to the notebook's output cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb954e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params (keeps previous behavior where params corresponds to idxAfterPrediction=5)\n",
    "params_default = {\n",
    "    \"idxAfterPrediction\": 5,\n",
    "    'timesteps': 90,\n",
    "    'target_option': 'last',\n",
    "    \"LoadupSamples_time_scaling_stretch\": True,\n",
    "    \"LoadupSamples_time_inc_factor\": 10,\n",
    "    \n",
    "    \"LSTM_units\": 32,\n",
    "    \"LSTM_num_layers\": 3,\n",
    "    \"LSTM_dropout\": 0.001,\n",
    "    \"LSTM_recurrent_dropout\": 0.001,\n",
    "    \"LSTM_learning_rate\": 0.001,\n",
    "    \"LSTM_optimizer\": \"adam\",\n",
    "    \"LSTM_bidirectional\": True,\n",
    "    \"LSTM_batch_size\": 2**12,\n",
    "    \"LSTM_epochs\": 10,\n",
    "    \"LSTM_l1\": 0.001,\n",
    "    \"LSTM_l2\": 0.001,\n",
    "    \"LSTM_inter_dropout\": 0.001,\n",
    "    \"LSTM_input_gaussian_noise\": 0.001,\n",
    "    \"LSTM_conv1d\": True,\n",
    "    \"LSTM_conv1d_kernel_size\": 3,\n",
    "    \"LSTM_loss\": \"mse\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05214fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_group = \"group_regOHLCV_over5years\"\n",
    "eval_date = datetime.date(year=2025, month=6, day=13)\n",
    "split_date = datetime.date(year=2023, month=12, day=31)\n",
    "\n",
    "studytime = 60*60*1\n",
    "studyname = f\"sandbox_lstm_optuna_{formatted_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3912a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 18:07:10,801] A new study created in RDB with name: sandbox_lstm_optuna_notebook-lstm-optuna-19aug25_1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-19 18:07:10,801 - A new study created in RDB with name: sandbox_lstm_optuna_notebook-lstm-optuna-19aug25_1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-19 18:07:22,120] Trial 0 failed with parameters: {'year_start': 2023, 'idxAfterPrediction': 4, 'LoadupSamples_time_inc_factor': 41, 'timesteps': 70, 'LSTM_learning_rate': 0.000649918985645458, 'LSTM_l1': 0.00047753902002221107, 'LSTM_l2': 0.0002814140456861457, 'LSTM_dropout': 0.0004739446332724232, 'LSTM_inter_dropout': 0.0001857324807671344, 'LSTM_recurrent_dropout': 0.041310111798629444, 'is_single_feature': False} because of the following error: AssertionError('Torch not compiled with CUDA enabled').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\KILightTouch\\AppData\\Local\\Temp\\ipykernel_9688\\1869135689.py\", line 51, in objective\n",
      "    model_lstm0, res_dict0 = mm.run_LSTM_torch(Xtrain, ytrain, Xtest, ytest, device=\"cuda\")\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\src\\predictionModule\\MachineModels.py\", line 489, in run_LSTM_torch\n",
      "    ).to(device)\n",
      "      ^^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1340, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 900, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 927, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1326, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 310, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-19 18:07:22,120 - Trial 0 failed with parameters: {'year_start': 2023, 'idxAfterPrediction': 4, 'LoadupSamples_time_inc_factor': 41, 'timesteps': 70, 'LSTM_learning_rate': 0.000649918985645458, 'LSTM_l1': 0.00047753902002221107, 'LSTM_l2': 0.0002814140456861457, 'LSTM_dropout': 0.0004739446332724232, 'LSTM_inter_dropout': 0.0001857324807671344, 'LSTM_recurrent_dropout': 0.041310111798629444, 'is_single_feature': False} because of the following error: AssertionError('Torch not compiled with CUDA enabled').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\KILightTouch\\AppData\\Local\\Temp\\ipykernel_9688\\1869135689.py\", line 51, in objective\n",
      "    model_lstm0, res_dict0 = mm.run_LSTM_torch(Xtrain, ytrain, Xtest, ytest, device=\"cuda\")\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\src\\predictionModule\\MachineModels.py\", line 489, in run_LSTM_torch\n",
      "    ).to(device)\n",
      "      ^^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1340, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 900, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 927, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1326, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 310, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-19 18:07:22,146] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-19 18:07:22,146 - Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 112\u001b[0m\n\u001b[0;32m    104\u001b[0m sampler \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m    105\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m    106\u001b[0m     study_name \u001b[38;5;241m=\u001b[39m studyname,\n\u001b[0;32m    107\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///sandbox_optuna.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[0;32m    111\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudytime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[4], line 51\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     48\u001b[0m mm \u001b[38;5;241m=\u001b[39m MachineModels(opt_params)\n\u001b[0;32m     50\u001b[0m starttime0 \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m---> 51\u001b[0m model_lstm0, res_dict0 \u001b[38;5;241m=\u001b[39m \u001b[43mmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_LSTM_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m preds_train0 \u001b[38;5;241m=\u001b[39m mm\u001b[38;5;241m.\u001b[39mpredict_LSTM_torch(model_lstm0, Xtrain, batch_size\u001b[38;5;241m=\u001b[39mopt_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m preds_test0 \u001b[38;5;241m=\u001b[39m mm\u001b[38;5;241m.\u001b[39mpredict_LSTM_torch(model_lstm0, Xtest, batch_size\u001b[38;5;241m=\u001b[39mopt_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\src\\predictionModule\\MachineModels.py:489\u001b[0m, in \u001b[0;36mMachineModels.run_LSTM_torch\u001b[1;34m(self, X_train, y_train, X_test, y_test, device)\u001b[0m\n\u001b[0;32m    473\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[0;32m    476\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_Torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlstm_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_conv1d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_conv1d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconv_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43minter_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minter_dropout\u001b[49m\n\u001b[1;32m--> 489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# Loss functions\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquantile_loss\u001b[39m(q):\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\KILightTouch\\Desktop\\RandomOdyssey\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    opt_params = params_default.copy()\n",
    "    opt_params[\"year_start\"] = trial.suggest_int(\"year_start\", 2019, 2023)\n",
    "    opt_params[\"idxAfterPrediction\"] = trial.suggest_int(\"idxAfterPrediction\", 3, 5, step=1)\n",
    "    opt_params[\"LoadupSamples_time_inc_factor\"] = trial.suggest_int(\"LoadupSamples_time_inc_factor\", 21, 71, step=5)\n",
    "    opt_params[\"timesteps\"] = trial.suggest_int(\"timesteps\", 50, 90, step=5)\n",
    "    opt_params[\"LSTM_units\"] = 16\n",
    "    opt_params[\"LSTM_num_layers\"] = 1\n",
    "    opt_params[\"LSTM_learning_rate\"] = trial.suggest_float(\"LSTM_learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    opt_params[\"LSTM_epochs\"] = 2\n",
    "    opt_params[\"LSTM_l1\"] = trial.suggest_float(\"LSTM_l1\", 1e-5, 1e-3, log=True)\n",
    "    opt_params[\"LSTM_l2\"] = trial.suggest_float(\"LSTM_l2\", 1e-4, 1e-1, log=True)\n",
    "    opt_params[\"LSTM_dropout\"] = trial.suggest_float(\"LSTM_dropout\", 1e-5, 1e-3, log=True)\n",
    "    opt_params[\"LSTM_inter_dropout\"] = trial.suggest_float(\"LSTM_inter_dropout\", 1e-4, 1e-1, log=True)\n",
    "    opt_params[\"LSTM_recurrent_dropout\"] = trial.suggest_float(\"LSTM_recurrent_dropout\", 1e-4, 1e-1, log=True)\n",
    "    opt_params[\"LSTM_conv1d_kernel_size\"] = 3\n",
    "    opt_params[\"is_single_feature\"] = trial.suggest_categorical(\"is_single_feature\", [True, False])\n",
    "\n",
    "    ls = LoadupSamples(\n",
    "        train_start_date=datetime.date(year=opt_params[\"year_start\"], month=1, day=1),\n",
    "        test_dates=[eval_date],\n",
    "        treegroup=None,\n",
    "        timegroup=stock_group,\n",
    "        params=opt_params,\n",
    "    )\n",
    "    ls.load_samples(main_path = \"../src/featureAlchemy/bin/\")\n",
    "\n",
    "    ls.split_dataset(\n",
    "        start_date=datetime.date(year=opt_params[\"year_start\"], month=1, day=1),\n",
    "        last_train_date=split_date,\n",
    "        last_test_date=eval_date,\n",
    "    )\n",
    "\n",
    "    Xtrain = ls.train_Xtime\n",
    "    ytrain = ls.train_ytime\n",
    "    Xtest = ls.test_Xtime\n",
    "    ytest = ls.test_ytime\n",
    "\n",
    "    true_res = ls.meta_pl_test\n",
    "\n",
    "    Xtrain = Xtrain[:, -opt_params[\"timesteps\"]:, :]\n",
    "    Xtest = Xtest[:, -opt_params[\"timesteps\"]:, :]\n",
    "\n",
    "    if opt_params[\"is_single_feature\"]:\n",
    "        Xtrain = Xtrain[:, :, [0]]\n",
    "        Xtest = Xtest[:, :, [0]]\n",
    "\n",
    "    mm = MachineModels(opt_params)\n",
    "\n",
    "    starttime0 = datetime.datetime.now()\n",
    "    model_lstm0, res_dict0 = mm.run_LSTM_torch(Xtrain, ytrain, Xtest, ytest, device=\"cuda\")\n",
    "    preds_train0 = mm.predict_LSTM_torch(model_lstm0, Xtrain, batch_size=opt_params[\"LSTM_batch_size\"], device=\"cuda\")\n",
    "    preds_test0 = mm.predict_LSTM_torch(model_lstm0, Xtest, batch_size=opt_params[\"LSTM_batch_size\"], device=\"cuda\")\n",
    "    endtime0 = datetime.datetime.now()\n",
    "\n",
    "    q = 0.90\n",
    "    mask_train_above0 = (preds_train0 >= np.quantile(preds_train0, q))\n",
    "    mask_pred_above0 = (preds_test0 >= np.quantile(preds_test0, q))\n",
    "    mask_pred_below0 = (preds_test0 < np.quantile(preds_test0, q))\n",
    "    true_res_masked_0 = true_res.filter(pl.Series(mask_pred_above0))\n",
    "    true_res_masked_below0 = true_res.filter(pl.Series(mask_pred_below0))\n",
    "\n",
    "    #run again\n",
    "    starttime1 = datetime.datetime.now()\n",
    "    model_lstm1, res_dict1 = mm.run_LSTM_torch(Xtrain[mask_train_above0], ytrain[mask_train_above0], Xtest[mask_pred_above0], ytest[mask_pred_above0], device=\"cuda\")\n",
    "    preds_test1 = mm.predict_LSTM_torch(model_lstm1, Xtest[mask_pred_above0], batch_size=opt_params[\"LSTM_batch_size\"], device=\"cuda\")\n",
    "    endtime1 = datetime.datetime.now()\n",
    "\n",
    "    mask_pred_above1 = (preds_test1 >= np.quantile(preds_test1, q))\n",
    "    mask_pred_below1 = (preds_test1 < np.quantile(preds_test1, q))\n",
    "    true_res_masked_1 = true_res_masked_0.filter(pl.Series(mask_pred_above1))\n",
    "    true_res_masked_below1 = true_res_masked_below0.filter(pl.Series(mask_pred_below1))\n",
    "\n",
    "    score = (np.mean(true_res_masked_1['target_ratio'].to_numpy())) ** (1/opt_params[\"idxAfterPrediction\"])\n",
    "\n",
    "    # Log some results\n",
    "    def quant_dis_in_mask(mask: np.ndarray, q: float) -> int:\n",
    "        if not mask.any():\n",
    "            return len(mask)\n",
    "        return np.quantile(np.abs(np.diff(np.where(mask)[0])), q)\n",
    "\n",
    "    full_mask = mask_pred_above0.copy()\n",
    "    full_mask[mask_pred_above0] = mask_pred_above1\n",
    "\n",
    "    logger.info(f\"Trial {trial.number} with params: {opt_params}\")\n",
    "    logger.info(f\"  Duration0: {endtime0 - starttime0}\")\n",
    "    logger.info(f\"  Duration1: {endtime1 - starttime1}\")\n",
    "    logger.info(f\"  Val RSME0 adjusted: {res_dict0['val_rmse']/opt_params['LoadupSamples_time_inc_factor']:.4f}\")\n",
    "    logger.info(f\"  Val RSME1 adjusted: {res_dict1['val_rmse']/opt_params['LoadupSamples_time_inc_factor']:.4f}\")\n",
    "    logger.info(f\"  Mean all prediction: {np.mean(true_res['target_ratio'].to_numpy()):.4f}\")\n",
    "    logger.info(f\"  Mean above prediction0: {np.mean(true_res_masked_0['target_ratio'].to_numpy()):.4f}\")\n",
    "    logger.info(f\"  Mean below prediction0: {np.mean(true_res_masked_below0['target_ratio'].to_numpy()):.4f}\")\n",
    "    logger.info(f\"  Mean above prediction1: {np.mean(true_res_masked_1['target_ratio'].to_numpy()):.4f}\")\n",
    "    logger.info(f\"  Mean below prediction1: {np.mean(true_res_masked_below1['target_ratio'].to_numpy()):.4f}\")\n",
    "    logger.info(f\"  Quantile 0.99 for distance in mask above: {quant_dis_in_mask(full_mask, 0.99)}\")\n",
    "    logger.info(f\"  Quantile 0.99 for distance in mask below: {quant_dis_in_mask(full_mask, 0.99)}\")\n",
    "    logger.info(f\"  Ratio for quantile-distance-to-length above: {quant_dis_in_mask(full_mask, 0.99) / len(full_mask):.4f}\")\n",
    "    logger.info(f\"  Ratio for quantile-distance-to-length below: {quant_dis_in_mask(full_mask, 0.99) / len(full_mask):.4f}\")\n",
    "    logger.info(f\"  Score: {score:.4f}\")\n",
    "\n",
    "    return score\n",
    "\n",
    "optuna.logging.enable_propagation()\n",
    "sampler = optuna.samplers.TPESampler(n_startup_trials=15)\n",
    "study = optuna.create_study(\n",
    "    study_name = studyname,\n",
    "    storage=\"sqlite:///sandbox_optuna.db\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    "    sampler=sampler,\n",
    ")\n",
    "study.optimize(objective, timeout=studytime)\n",
    "\n",
    "logger.info(f\"Best parameters: {study.best_params}\")\n",
    "logger.info(f\"Best score: {study.best_value}\")\n",
    "\n",
    "df: pd.DataFrame = study.trials_dataframe()\n",
    "logger.info(\"\\nTrials DataFrame:\")\n",
    "logger.info(df.sort_values(\"value\").to_string())\n",
    "\n",
    "param_importances = optuna.importance.get_param_importances(study)\n",
    "logger.info(\"Parameter Importances:\")\n",
    "for key, value in param_importances.items():\n",
    "    logger.info(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9856fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f\"sandbox_lstm_optuna_{formatted_str}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a1e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16 18:18:25,292 - NaN values found in training time features. 28 Samples removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16 18:18:42,097 - Epoch 1/2 — Train RMSE: 0.7566 — Validation RMSE: 0.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 1/2 [00:11<00:11, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16 18:18:53,391 - Epoch 2/2 — Train RMSE: 0.6707 — Validation RMSE: 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 2/2 [00:22<00:00, 11.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run with best parameters\n",
    "best_params = {**params_default, **study.best_params.copy()}\n",
    "best_params[\"LSTM_units\"] = 16\n",
    "best_params[\"LSTM_epochs\"] = 2\n",
    "best_params[\"LSTM_conv1d_kernel_size\"] = 3\n",
    "best_params[\"LSTM_num_layers\"] = 1\n",
    "\n",
    "ls = LoadupSamples(\n",
    "    train_start_date=datetime.date(year=best_params[\"year_start\"], month=1, day=1),\n",
    "    test_dates=[eval_date],\n",
    "    group=stock_group,\n",
    "    group_type=\"Time\",\n",
    "    params=best_params,\n",
    ")\n",
    "ls.load_samples(main_path=\"../src/featureAlchemy/bin/\")\n",
    "\n",
    "ls.split_dataset(\n",
    "    start_date=datetime.date(year=best_params[\"year_start\"], month=1, day=1),\n",
    "    last_train_date=split_date,\n",
    "    last_test_date=eval_date,\n",
    ")\n",
    "\n",
    "Xtrain = ls.train_Xtime\n",
    "ytrain = ls.train_ytime\n",
    "Xtest = ls.test_Xtime\n",
    "ytest = ls.test_ytime\n",
    "\n",
    "Xtrain = Xtrain[:, -best_params[\"timesteps\"]:, :]\n",
    "Xtest = Xtest[:, -best_params[\"timesteps\"]:, :]\n",
    "\n",
    "if best_params[\"is_single_feature\"]:\n",
    "    Xtrain = Xtrain[:, :, [0]]\n",
    "    Xtest = Xtest[:, :, [0]]\n",
    "\n",
    "mm = MachineModels(best_params)\n",
    "model_lstm, res_dict = mm.run_LSTM_torch(Xtrain, ytrain, Xtest, ytest, device=\"cuda\")\n",
    "preds = mm.predict_LSTM_torch(model_lstm, Xtest, batch_size=best_params[\"LSTM_batch_size\"], device=\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f463c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16 18:33:38,602 -   Val RSME adjusted: 0.0132\n",
      "2025-08-16 18:33:38,604 -   Mean all prediction: 1.0010\n",
      "2025-08-16 18:33:38,605 -   Mean above prediction: 1.0101\n",
      "2025-08-16 18:33:38,605 -   Mean below prediction: 1.0001\n",
      "2025-08-16 18:33:38,608 -   Quantile 0.99 in mask above: 450.27999999999884\n",
      "2025-08-16 18:33:38,609 -   Quantile 0.99 in mask below: 427.0\n",
      "2025-08-16 18:33:38,611 -   Ratio for quantile to length above: 0.0007\n",
      "2025-08-16 18:33:38,612 -   Ratio for quantile to length below: 0.0006\n",
      "2025-08-16 18:33:38,612 -   Score: 1.0025\n"
     ]
    }
   ],
   "source": [
    "q = 0.98\n",
    "mask_pred_above = (preds >= np.quantile(preds, q))\n",
    "mask_pred_below = (preds <= np.quantile(preds, 1-q))\n",
    "true_res = ls.meta_pl_test\n",
    "true_res_masked_above = true_res.filter(pl.Series(mask_pred_above))\n",
    "true_res_masked_below = true_res.filter(pl.Series(mask_pred_below))\n",
    "score = (np.mean(true_res_masked_above['target_ratio'].to_numpy())) ** (1/best_params[\"idxAfterPrediction\"])\n",
    "# Log some results\n",
    "def quant_dis_in_mask(mask: np.ndarray, q: float) -> int:\n",
    "    if not mask.any():\n",
    "        return len(mask)\n",
    "    return np.quantile(np.abs(np.diff(np.where(mask)[0])), q)\n",
    "logger.info(f\"  Val RSME adjusted: {res_dict['val_rmse']/best_params['LoadupSamples_time_inc_factor']:.4f}\")\n",
    "logger.info(f\"  Mean all prediction: {np.mean(true_res['target_ratio'].to_numpy()):.4f}\")\n",
    "logger.info(f\"  Mean above prediction: {np.mean(true_res_masked_above['target_ratio'].to_numpy()):.4f}\")\n",
    "logger.info(f\"  Mean below prediction: {np.mean(true_res_masked_below['target_ratio'].to_numpy()):.4f}\")\n",
    "logger.info(f\"  Quantile 0.99 in mask above: {quant_dis_in_mask(mask_pred_above, 0.99)}\")\n",
    "logger.info(f\"  Quantile 0.99 in mask below: {quant_dis_in_mask(mask_pred_below, 0.99)}\")\n",
    "logger.info(f\"  Ratio for quantile to length above: {quant_dis_in_mask(mask_pred_above, 0.99) / len(mask_pred_above):.4f}\")\n",
    "logger.info(f\"  Ratio for quantile to length below: {quant_dis_in_mask(mask_pred_below, 0.99) / len(mask_pred_below):.4f}\")\n",
    "logger.info(f\"  Score: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
